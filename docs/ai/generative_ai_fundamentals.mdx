---
slug: generative_ai_fundamentals
title: 🚀 Generative AI Fundamentals
authors: [bundabergman]
tags: [ai, fundamentals]
---

## 생성형 AI란?

생성적 AI는 새로운 원본 콘텐츠를 생성할 수 있는 기회를 열어주는 인공지능의 흥미로운 분야로, 작성된 텍스트에서부터 멋진 비주얼, 심지어 컴퓨터 생성 음악에 이르기까지 다양합니다. 이는 단순한 분석 작업을 넘어 창의적인 프로세스에 참여함으로써 AI의 혁신적인 측면을 보여줍니다.

### 기술 용어 설명

- 텍스트 생성(Text Generation): 이는 컴퓨터가 주제와 관련된 의미 있는 텍스트를 작성하도록 하는 것으로, 자동 이야기꾼과 유사합니다.

- 이미지 생성(Image Generation): 이는 컴퓨터가 새로운 그림을 만들거나 기존의 그림을 변경할 수 있게 해주며, 마치 디지털 아티스트가 가상 붓을 사용하는 것과 같습니다.
 
- 코드 생성(Code Generation): 이는 프로그래밍을 위한 생성적 AI로, 컴퓨터가 새로운 코드를 작성하는 데 도움을 줍니다.
 
- 오디오 생성(Audio Generation): 컴퓨터는 소리나 음악을 생성할 수도 있으며, 이는 마치 로봇 작곡가가 자신의 멜로디를 만드는 것과 비슷합니다.
 
- 챗 GPT(Chat GPT): OpenAI에서 개발한 언어 모델로, 대화에서 인간이 제공할 수 있는 응답을 생성할 수 있으며, 문맥에 따라 다음 단어를 예측하여 응답을 만듭니다.
 
- DALL·E: OpenAI의 AI 프로그램으로, 텍스트 설명으로부터 이미지를 생성하며, 시각 예술에서의 창의성을 모방합니다.
 
- GitHub Copilot: 개발자가 더 효율적이고 오류를 줄이면서 코드를 작성할 수 있도록 코드 스니펫을 제안하고 코드 라인을 완성하는 코딩 보조 도구입니다.
 
- 맥락적 제안(Contextual Suggestions): Copilot과 같은 AI 도구가 제공하는 추천으로, 사용자가 작업 중인 현재의 작업이나 맥락과 관련이 있습니다.

## AI 및 머신러닝 타임라인

AI 및 머신러닝 타임라인은 1950년대의 퍼셉트론과 같은 초기 발전에서 시작하여, 생성적 AI의 최근 혁신에 이르기까지 다양한 도전과 혁신을 거쳐온 기술적 돌파구의 여정입니다. 이 타임라인은 AI의 진화에 관련된 인내와 독창성을 보여주며, 각 10년이 어떻게 이전 10년을 기반으로 하여 오늘날의 흥미로운 능력에 도달했는지를 강조합니다.

### 기술 용어 설명

- 퍼셉트론(Perceptron): 입력이 특정 클래스에 속하는지 여부를 결정할 수 있는 초기 유형의 신경망 구성 요소로, 입력은 숫자 값으로 표현됩니다.

- 신경망(Neural Networks): 인공 뉴런 간의 연결을 조정하여 데이터에서 학습할 수 있는 인간 두뇌를 모델로 한 컴퓨터 시스템입니다.

- 역전파(Back Propagation): 손실 함수의 기울기를 계산하여 가중치를 조정함으로써 모델을 개선하는 데 사용되는 인공 신경망의 방법입니다.

- 통계적 머신러닝(Statistical Machine Learning): 데이터에서 학습하는 알고리즘을 사용하여 분석 모델 구축을 자동화하는 데이터 분석 방법입니다.

- 딥러닝(Deep Learning): 소프트웨어가 다층 신경망에 방대한 양의 데이터를 노출시켜 스스로 작업을 수행하도록 허용하는 알고리즘으로 구성된 머신러닝의 하위 집합입니다.

- 생성적 적대 신경망(Generative Adversarial Networks, GANs): 생성기와 판별기라는 두 네트워크가 동시에 훈련되는 머신러닝 모델의 한 종류로, 제로섬 게임 프레임워크에서 작동합니다.

- 트랜스포머(Transformer): 순차 데이터를 처리하는 딥러닝 모델의 한 종류로, 자연어 처리 작업에서 높은 성능으로 주목받고 있습니다.

## 생성적 AI 모델을 훈련하는 방법

생성적 AI 모델을 훈련하는 흥미로운 세계는 컴퓨터가 방대한 데이터셋에서 학습하여 텍스트나 이미지와 같은 새로운 콘텐츠를 생성하도록 가르치는 것입니다. 이 훈련은 AI가 인간 언어와 시각 예술에서 발견되는 복잡한 패턴을 이해하고 재현하는 데 도움을 줍니다. 이 과정은 복잡하지만 매우 보람이 있으며, 놀랍도록 현실감 있는 출력을 생성할 수 있는 AI로 이어집니다.

### 기술 용어 설명:

- 대형 언어 모델(Large Language Models, LLMs): 이는 방대한 양의 텍스트 데이터로 훈련되어 인간 언어를 이해하고 생성하도록 특별히 설계된 AI 모델입니다.

- 변분 오토인코더(Variational Autoencoders, VAEs): 새로운 이미지를 생성하는 데 사용할 수 있는 AI 모델의 한 종류입니다. 두 가지 주요 부분으로 구성되어 있습니다: 인코더는 데이터를 더 간단한 형태로 축소하고, 디코더는 이를 확장하여 새로운 콘텐츠를 생성합니다.

- 잠재 공간(Latent Space): 오토인코더가 더 간단하고 작은 형태로 생성하는 데이터의 압축된 표현으로, 새로운 데이터를 재구성하거나 생성하는 데 필요한 가장 중요한 특징을 포착합니다.

- 파라미터(Parameters): 파라미터는 모델이 훈련 중에 학습하는 변수입니다. 이들은 모델 내부에 있으며 학습 과정을 통해 조정됩니다. 신경망의 맥락에서 파라미터는 일반적으로 가중치와 바이어스를 포함합니다.

- 가중치(Weights): 가중치는 입력 데이터의 계수입니다. 이들은 계산에 사용되어 입력 변수가 모델의 출력에 미치는 중요성이나 영향을 결정합니다. 신경망에서는 뉴런 간의 각 연결에 관련된 가중치가 있습니다.

- 바이어스(Biases): 바이어스는 뉴런에 부착된 추가 상수로, 활성화 함수가 적용되기 전에 가중치가 적용된 입력에 추가됩니다. 바이어스는 모든 입력이 0일 때에도 비제로 출력을 보장합니다.

- 하이퍼파라미터(Hyperparameters): 하이퍼파라미터는 파라미터와 달리 데이터에서 학습되지 않습니다. 이들은 학습 과정의 설정이나 구성에 더 가깝습니다. 훈련 과정 전에 설정되며 훈련 중에는 일정하게 유지됩니다. 이들은 모델 외부에 있으며 학습 과정을 제어하는 데 사용됩니다.